{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b51a29a2-85c6-4bab-9732-9cfc4032f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import yaml\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torchmetrics import Dice, JaccardIndex\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.networks.utils import one_hot\n",
    "from monai.losses import DiceCELoss, DiceFocalLoss\n",
    "\n",
    "from ReadData.create_ID_list_selected_dataset import create_list_ID_training\n",
    "from utils.data import Data\n",
    "\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import models.regionvit_unet.regionvit_unet as regionvit_unet\n",
    "from models.regionvit_fpn.fpn.model import FPN\n",
    "from models.swin_unet.config_swin_transformer import get_config\n",
    "from models.swin_unet.vision_transformer import SwinUnet as ViT_seg\n",
    "from monai.networks.nets import BasicUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c1a2e6-a874-49f0-977e-63ba5ce6fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fParseConfig(sFile):\n",
    "    # get config file\n",
    "    with open(sFile, 'r') as ymlfile:\n",
    "        cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba195c3-b349-4fad-8329-9fe0ffeeb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# pixel accuracy and mean Intersection over Union used as evaluation metrics\n",
    "\n",
    "def pixel_accuracy(output, mask):\n",
    "    with torch.no_grad():\n",
    "        output = torch.argmax(output, dim=1)\n",
    "        mask = torch.argmax(mask, dim=1)\n",
    "        correct = torch.eq(output, mask).int()\n",
    "        accuracy = float(correct.sum()) / float(correct.numel())\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=2):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = torch.argmax(mask, dim=1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes):  # loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0:  # no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union + smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60499a74-2e3d-4d6f-9e8a-7e55c40901fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selectedDatasets {'t1_tse_tra_Kopf_0002': <utils.data.Dataset object at 0x7f20e875e070>, 't1_tse_tra_Kopf_Motion_0003': <utils.data.Dataset object at 0x7f20e875e0d0>}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/students/studborst1/data/MRPhysics_nifti/raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dearadhp/italy/Untitled.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdestc0strapp15/home/dearadhp/italy/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=247'>248</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(cfg[\u001b[39m'\u001b[39m\u001b[39mSEED\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdestc0strapp15/home/dearadhp/italy/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=248'>249</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mmanual_seed(cfg[\u001b[39m'\u001b[39m\u001b[39mSEED\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bdestc0strapp15/home/dearadhp/italy/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=250'>251</a>\u001b[0m data \u001b[39m=\u001b[39m Data(cfg)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdestc0strapp15/home/dearadhp/italy/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=251'>252</a>\u001b[0m partition \u001b[39m=\u001b[39m create_list_ID_training(cfg)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdestc0strapp15/home/dearadhp/italy/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=253'>254</a>\u001b[0m \u001b[39mif\u001b[39;00m cfg[\u001b[39m'\u001b[39m\u001b[39mMode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdestc0strapp15/home/dearadhp/italy/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=254'>255</a>\u001b[0m     \u001b[39m# load training and validation data\u001b[39;00m\n",
      "File \u001b[0;32m~/italy/utils/data.py:110\u001b[0m, in \u001b[0;36mData.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatchSizeX, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatchSizeY \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatchsize[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatchsize[\u001b[39m1\u001b[39m]\n\u001b[1;32m    109\u001b[0m \u001b[39m# # parsable list of data files\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_get_ID_list()\n\u001b[1;32m    111\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist_ID)\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist_ID)\n",
      "File \u001b[0;32m~/italy/utils/data.py:126\u001b[0m, in \u001b[0;36mData.new_get_ID_list\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m database \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg[\u001b[39m'\u001b[39m\u001b[39mDatabase\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    125\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg[database][\u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mfor\u001b[39;00m pat \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(path):\n\u001b[1;32m    127\u001b[0m         pat_path \u001b[39m=\u001b[39m path \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39msep \u001b[39m+\u001b[39m pat\n\u001b[1;32m    129\u001b[0m         \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg[database][\u001b[39m'\u001b[39m\u001b[39mdatasets\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/students/studborst1/data/MRPhysics_nifti/raw'"
     ]
    }
   ],
   "source": [
    "def predict(model, test_loader, criterion):\n",
    "    test_loss = 0.0\n",
    "    test_mIoU_macro = 0.0\n",
    "    test_hd95 = 0.0\n",
    "    test_dice_macro = 0.0\n",
    "    test_acc = 0.0\n",
    "    test_sensitivity = 0.0\n",
    "    test_specificity = 0.0\n",
    "    test_precision = 0.0\n",
    "    test_negative_predictive_value = 0.0\n",
    "    test_loss_list = []\n",
    "    test_mIoU_macro_list = []\n",
    "    test_hd95_list = []\n",
    "    test_dice_macro_list = []\n",
    "    test_acc_list = []\n",
    "    test_sensitivity_list = []\n",
    "    test_specificity_list = []\n",
    "    test_precision_list = []\n",
    "    test_negative_predictive_value_list = []\n",
    "\n",
    "    test_hausdorff = monai.metrics.HausdorffDistanceMetric(include_background=True, reduction=\"mean\", percentile=95.0,\n",
    "                                                           get_not_nans=False)\n",
    "    test_dice = Dice(num_classes=2, average='macro').to(device)\n",
    "\n",
    "    model.eval()  # Optional when not using Model Specific layer\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            output_one_hot = model(images)\n",
    "\n",
    "            labels_binarized_one_hot = one_hot(labels, num_classes=2, dim=1)\n",
    "\n",
    "            loss = criterion(output_one_hot, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_loss_list.append(loss)\n",
    "\n",
    "            output_one_hot = torch.nn.functional.softmax(output_one_hot)\n",
    "            output_binarized_one_hot = (output_one_hot > 0.5)\n",
    "            test_mIoU_macro += mIoU(output_one_hot, labels_binarized_one_hot)\n",
    "            test_mIoU_macro_list.append(mIoU(output_one_hot, labels_binarized_one_hot))\n",
    "            test_hausdorff(y_pred=output_binarized_one_hot, y=labels_binarized_one_hot)\n",
    "            test_hd95 += test_hausdorff.aggregate().item()\n",
    "            test_hd95_list.append(test_hausdorff.aggregate().item())\n",
    "            test_dice_macro += test_dice(preds=output_one_hot, target=labels.type(torch.int8))\n",
    "            test_dice_macro_list.append(test_dice(preds=output_one_hot, target=labels.type(torch.int8)))\n",
    "            test_acc += pixel_accuracy(output_one_hot, labels_binarized_one_hot)\n",
    "            test_acc_list.append(pixel_accuracy(output_one_hot, labels_binarized_one_hot))\n",
    "\n",
    "            output = torch.argmax(output_one_hot, dim=1)\n",
    "            output = torch.unsqueeze(output, dim=1)\n",
    "\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(output, labels.long(), mode='binary', threshold=0.5)\n",
    "            test_sensitivity += smp.metrics.functional.sensitivity(tp, fp, fn, tn, reduction='micro-imagewise')\n",
    "            test_sensitivity_list.append(smp.metrics.functional.sensitivity(tp, fp, fn, tn, reduction='micro-imagewise'))\n",
    "            test_specificity += smp.metrics.functional.specificity(tp, fp, fn, tn, reduction='micro-imagewise')\n",
    "            test_specificity_list.append(smp.metrics.functional.specificity(tp, fp, fn, tn, reduction='micro-imagewise'))\n",
    "            test_precision += smp.metrics.functional.precision(tp, fp, fn, tn, reduction='micro-imagewise')\n",
    "            test_precision_list.append(smp.metrics.functional.precision(tp, fp, fn, tn, reduction='micro-imagewise'))\n",
    "            test_negative_predictive_value += smp.metrics.functional.negative_predictive_value(tp, fp, fn, tn, reduction='micro-imagewise')\n",
    "            test_negative_predictive_value_list.append(smp.metrics.functional.negative_predictive_value(tp, fp, fn, tn, reduction='micro-imagewise'))\n",
    "\n",
    "    raw_data = {\n",
    "        'loss': [loss.cpu().numpy() / len(test_loader)],\n",
    "        'mIoU_macro': [test_mIoU_macro / len(test_loader)],\n",
    "        'dice_macro': [test_dice_macro.cpu().detach().numpy() / len(test_loader)],\n",
    "        'accuracy':  [test_acc / len(test_loader)],\n",
    "        'hd95': [test_hd95 / len(test_loader)],\n",
    "        'sensitivity': [test_sensitivity.cpu().detach().numpy() / len(test_loader)],\n",
    "        'specificity': [test_specificity.cpu().detach().numpy() / len(test_loader)],\n",
    "        'precision': [test_precision.cpu().detach().numpy() / len(test_loader)],\n",
    "        'negative_predictive_value': [test_negative_predictive_value.cpu().detach().numpy() / len(test_loader)],\n",
    "      }\n",
    "\n",
    "    test_loss_list = torch.tensor(test_loss_list, device='cpu')\n",
    "    test_mIoU_macro_list = torch.tensor(test_mIoU_macro_list, device='cpu')\n",
    "    test_dice_macro_list = torch.tensor(test_dice_macro_list, device='cpu')\n",
    "    test_acc_list = torch.tensor(test_acc_list, device='cpu')\n",
    "    test_hd95_list = torch.tensor(test_hd95_list, device='cpu')\n",
    "    test_sensitivity_list = torch.tensor(test_sensitivity_list, device='cpu')\n",
    "    test_specificity_list = torch.tensor(test_specificity_list, device='cpu')\n",
    "    test_precision_list = torch.tensor(test_precision_list, device='cpu')\n",
    "    test_negative_predictive_value_list = torch.tensor(test_negative_predictive_value_list, device='cpu')\n",
    "    raw_data_slice = {\n",
    "        'loss': test_loss_list.numpy(),\n",
    "        'mIoU_macro': test_mIoU_macro_list.numpy(),\n",
    "        'dice_macro': test_dice_macro_list.numpy(),\n",
    "        'accuracy':  test_acc_list.numpy(),\n",
    "        'hd95': test_hd95_list.numpy(),\n",
    "        'sensitivity': test_sensitivity_list.numpy(),\n",
    "        'specificity': test_specificity_list.numpy(),\n",
    "        'precision': test_precision_list.numpy(),\n",
    "        'negative_predictive_value': test_negative_predictive_value_list.numpy(),\n",
    "      }\n",
    "\n",
    "    df = pd.DataFrame(raw_data, columns=['loss', 'mIoU_macro', 'dice_macro', 'accuracy', 'hd95', 'sensitivity',\n",
    "                                         'specificity', 'precision', 'negative_predictive_value'])\n",
    "\n",
    "    df_slice = pd.DataFrame(raw_data_slice, columns=['loss', 'mIoU_macro', 'dice_macro', 'accuracy', 'hd95', 'sensitivity',\n",
    "                                         'specificity', 'precision', 'negative_predictive_value'])\n",
    "\n",
    "    df.to_csv(cfg['CSV'] + '_average.csv', index=True)\n",
    "    df_slice.to_csv(cfg['CSV'] + '_slicewise.csv', index=True)\n",
    "\n",
    "    print(\"Test Loss: {:.3f}..\".format(test_loss / len(test_loader)),\n",
    "          \"Test mIoU macro: {:.3f}..\".format(test_mIoU_macro / len(test_loader)),\n",
    "          \"Test Dice macro: {:.3f}..\".format(test_dice_macro / len(test_loader)),\n",
    "          \"Test hd95: {:.3f}..\".format(test_hd95 / len(test_loader)),\n",
    "          \"Test Acc:{:.3f}..\".format(test_acc / len(test_loader)),\n",
    "          \"Test Sensitivity:{:.3f}..\".format(test_sensitivity / len(test_loader)),\n",
    "          \"Test Specificity:{:.3f}..\".format(test_specificity / len(test_loader)),\n",
    "          \"Test Precision:{:.3f}..\".format(test_precision / len(test_loader)),\n",
    "          \"Test Negative Predictive Value:{:.3f}..\".format(test_negative_predictive_value / len(test_loader)))\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# model training\n",
    "\n",
    "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    val_hausdorff = monai.metrics.HausdorffDistanceMetric(include_background=True, reduction=\"mean\", percentile=95.0, get_not_nans=False)\n",
    "    val_dice = Dice(num_classes=2, average='macro').to(device)\n",
    "    val_jc = JaccardIndex(num_classes=2, average='micro').to(device)\n",
    "\n",
    "    min_loss = np.inf\n",
    "    decrease = 1\n",
    "    not_improve = 0\n",
    "    lrs = []\n",
    "\n",
    "    columns = [\"image\", \"prediction\", \"ground truth\"]\n",
    "    wandb_table = wandb.Table(columns=columns)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        train_mIoU_macro = 0.0\n",
    "        train_acc = 0.0\n",
    "        model.train()  # Optional when not using Model Specific layer\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output_one_hot = model(images)\n",
    "\n",
    "            labels_binarized_one_hot = one_hot(labels, num_classes=2, dim=1)\n",
    "\n",
    "            loss = criterion(output_one_hot, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            clip = cfg['Clip']\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            output_one_hot = torch.nn.functional.softmax(output_one_hot)\n",
    "            train_mIoU_macro += mIoU(output_one_hot, labels_binarized_one_hot).item()\n",
    "            train_acc += pixel_accuracy(output_one_hot, labels_binarized_one_hot)\n",
    "\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        # validation during training\n",
    "        idx = 0\n",
    "        val_loss = 0.0\n",
    "        val_mIoU_macro = 0.0\n",
    "        val_mIoU_micro = 0.0\n",
    "        val_hd95 = 0.0\n",
    "        val_dice_macro = 0.0\n",
    "        val_acc = 0.0\n",
    "        model.eval()\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            with torch.no_grad():\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                output_one_hot = model(images)\n",
    "\n",
    "                labels_binarized_one_hot = one_hot(labels, num_classes=2, dim=1)\n",
    "\n",
    "                loss = criterion(output_one_hot, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                output_one_hot = torch.nn.functional.softmax(output_one_hot)\n",
    "                output_binarized_one_hot = (output_one_hot > 0.5)\n",
    "                val_mIoU_macro += mIoU(output_one_hot, labels_binarized_one_hot).item()\n",
    "                val_mIoU_micro += val_jc(preds=output_one_hot, target=labels.type(torch.int8)).item()\n",
    "                val_hausdorff(y_pred=output_binarized_one_hot, y=labels_binarized_one_hot)\n",
    "                val_hd95 += val_hausdorff.aggregate().item()\n",
    "                val_dice_macro += val_dice(preds=output_one_hot, target=labels.type(torch.int8)).item()\n",
    "                val_acc += pixel_accuracy(output_one_hot, labels_binarized_one_hot)\n",
    "\n",
    "                # plot some pictures in wandb to see how the model performance for validation set\n",
    "                if idx % 10 == 0:\n",
    "                    image_wb = images[1,:,:,:].cpu().detach().numpy().transpose(1,2,0)\n",
    "                    pred_wb = torch.argmax(output_one_hot[1,:,:,:], dim=0)\n",
    "                    pred_wb = pred_wb.cpu().detach().numpy()\n",
    "                    label_wb = labels[1,:,:,:].type(torch.FloatTensor)\n",
    "                    label_wb = label_wb.cpu().detach().numpy().transpose(1,2,0)\n",
    "                    wandb_table.add_data(wandb.Image(image_wb), wandb.Image(pred_wb), wandb.Image(label_wb))\n",
    "                    new_table = wandb.Table(columns=wandb_table.columns, data=wandb_table.data)\n",
    "                    wandb.log({\"validation samples\": new_table}, commit=False)\n",
    "\n",
    "                idx += 1\n",
    "\n",
    "        # save best performing models\n",
    "        if min_loss > (val_loss / len(val_loader)):\n",
    "            print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (val_loss / len(val_loader))))\n",
    "            min_loss = (val_loss / len(val_loader))\n",
    "            decrease += 1\n",
    "            if decrease % 2 == 0:\n",
    "                print('saving model...')\n",
    "                torch.save(model, cfg['SaveModel'] + 'mIoU_macro-{:.3f}.pt'.format(val_mIoU_macro / len(val_loader)))\n",
    "                torch.save(model, cfg['SaveModel'] + 'pixel_acc-{:.3f}.pt'.format(val_acc / len(val_loader)))\n",
    "\n",
    "        if (val_loss / len(val_loader)) > min_loss:\n",
    "            not_improve += 1\n",
    "            min_loss = (val_loss / len(val_loader))\n",
    "            print(f'Loss Not Decrease for {not_improve} time')\n",
    "            if not_improve == 100:\n",
    "                print('Loss not decrease for 50 times, Stop Training')\n",
    "                break\n",
    "\n",
    "        print(\"Epoch:{}/{}..\".format(e + 1, epochs),\n",
    "              \"Train Loss: {:.3f}..\".format(train_loss / len(train_loader)),\n",
    "              \"Val Loss: {:.3f}..\".format(val_loss / len(val_loader)),\n",
    "              \"Val mIoU: {:.3f}..\".format(val_mIoU_macro / len(val_loader)),\n",
    "              \"Val Acc:{:.3f}..\".format(val_acc / len(val_loader)),\n",
    "              \"Time: {:.2f}sec\".format(time.time() - t0))\n",
    "\n",
    "        # log data for wandb for better visualization and comparison between runs and models\n",
    "        wandb.log({'train loss': train_loss / len(train_loader), 'train accuracy': train_acc / len(train_loader),\n",
    "                   'val loss': val_loss / len(val_loader), 'train mIoU macro': train_mIoU_macro / len(train_loader),\n",
    "                   'val mIoU macro': val_mIoU_macro / len(val_loader), 'val accuracy (dice micro)': val_acc / len(val_loader),\n",
    "                   'val mIoU micro': val_mIoU_micro / len(val_loader), 'val dice macro': val_dice_macro / len(val_loader),\n",
    "                   'val hd95': val_hd95 / len(val_loader), 'learning rate': get_lr(optimizer)})\n",
    "\n",
    "    print('Training finished!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cfg = fParseConfig(r\"/home/dearadhp/italy/config.yml\")\n",
    "\n",
    "    device = torch.device(cfg['GPU'])\n",
    "    random.seed(cfg['SEED'])\n",
    "    np.random.seed(cfg['SEED'])\n",
    "    torch.manual_seed(cfg['SEED'])\n",
    "    torch.cuda.manual_seed(cfg['SEED'])\n",
    "\n",
    "    data = Data(cfg)\n",
    "    partition = create_list_ID_training(cfg)\n",
    "\n",
    "    if cfg['Mode'] == 'training':\n",
    "        # load training and validation data\n",
    "        images_patches_list, mask_patches_list = data.process_image_data(partition['train'])\n",
    "        train_data = [{\"image\": img, \"label\": label} for img, label in zip(images_patches_list, mask_patches_list)]\n",
    "\n",
    "        train_data, val_data = train_test_split(train_data, test_size=cfg['Train_test_ratio'], random_state=cfg['SEED'])\n",
    "\n",
    "        train_dataset_local = data.create_image_space_train_dataset(train_data)\n",
    "        validation_dataset_local = data.create_image_space_test_dataset(val_data)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset_local, batch_size=cfg['BatchSize'], shuffle=True,\n",
    "                                  num_workers=2, pin_memory=True)\n",
    "        val_loader = DataLoader(validation_dataset_local, batch_size=cfg['BatchSize'], shuffle=False,\n",
    "                                num_workers=4, pin_memory=True)\n",
    "\n",
    "        # select model\n",
    "        if cfg['Model'] == 'UNet':\n",
    "            model = BasicUNet(spatial_dims=2, in_channels=1, out_channels=2, features=(32, 64, 128, 256, 512, 64),\n",
    "                              upsample='deconv')\n",
    "        elif cfg['Model'] == 'Swin_UNet':\n",
    "            config = get_config()\n",
    "            model = ViT_seg(config, img_size=224, num_classes=cfg['Classes']).to(device)\n",
    "        elif cfg['Model'] == 'RegionViT_FPN':\n",
    "            model = FPN(encoder_name='regionvit', encoder_depth=5, encoder_weights='None', decoder_pyramid_channels=512,\n",
    "                        decoder_segmentation_channels=128, in_channels=512, classes=2, activation=None)\n",
    "        elif cfg['Model'] == 'RegionViT_UNet':\n",
    "            model = regionvit_unet.RegionViT_UNET()\n",
    "        else:\n",
    "            print('No model found')\n",
    "\n",
    "        model = model.to(device)\n",
    "\n",
    "        # select optimizer\n",
    "        if cfg['Optimizer'] == 'SGD':\n",
    "            optimizer = optim.SGD(model.parameters(), lr=cfg['LearningRate'], momentum=0.9, weight_decay=1e-4,\n",
    "                                  nesterov=True)\n",
    "            scheduler = OneCycleLR(optimizer, max_lr=cfg['LearningRate'], epochs=cfg['Epochs'],\n",
    "                                   steps_per_epoch=len(train_loader), div_factor=cfg['DivFactor'])\n",
    "        elif cfg['Optimizer'] == 'AdamW':\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=cfg['LearningRate'], betas=(0.9, 0.999), eps=1e-08,\n",
    "                                    weight_decay=1e-4)\n",
    "            scheduler = OneCycleLR(optimizer, max_lr=cfg['LearningRate'], epochs=cfg['Epochs'],\n",
    "                                   steps_per_epoch=len(train_loader), div_factor=cfg['DivFactor'])\n",
    "\n",
    "        # select loss function\n",
    "        if cfg['LossFunction'] == 'DiceCELoss':\n",
    "            criterion = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "        elif cfg['LossFunction'] == 'DiceFocalLoss':\n",
    "            criterion = DiceFocalLoss(to_onehot_y=True, focal_weight=[10, 0.1])\n",
    "\n",
    "        # wandb\n",
    "        config = {\"Epochs\": cfg['Epochs'], \"BatchSize\": cfg['BatchSize'], \"ImageSize\": cfg['PatchSize'],\n",
    "                  \"Optimizer\": cfg['Optimizer'], \"MaxLearningRate\": cfg['LearningRate'], \"DivFactor\": cfg['DivFactor'],\n",
    "                  \"PatchOverlap_NAKO\": cfg['PatchOverlap_NAKO'], \"PatchOverlap_MRP\": cfg['PatchOverlap_MRP'],\n",
    "                  \"HoldOutPatient\": cfg['SelectedPatient'], \"Scheduler\": cfg['Scheduler'],\n",
    "                  \"Normalized\": cfg['Normalized'], \"Clip\": cfg['Clip']}\n",
    "\n",
    "        wandb.init(settings=wandb.Settings(start_method=\"fork\"), config=config, project=cfg['Wandb'])\n",
    "        wandb.watch_called = False\n",
    "\n",
    "        # start training\n",
    "        fit(cfg['Epochs'], model, train_loader, val_loader, criterion, optimizer, scheduler)\n",
    "\n",
    "    if cfg['Mode'] == 'prediction':\n",
    "        # select model and get weights from checkpoint\n",
    "        if cfg['Model'] == 'UNet':\n",
    "            model = BasicUNet(spatial_dims=2, in_channels=1, out_channels=2, features=(32, 64, 128, 256, 512, 64),\n",
    "                              upsample='deconv')\n",
    "        elif cfg['Model'] == 'Swin_UNet':\n",
    "            config = get_config()\n",
    "            model = ViT_seg(config, img_size=224, num_classes=cfg['Classes']).to(device)\n",
    "        elif cfg['Model'] == 'RegionViT_FPN':\n",
    "            model = FPN(encoder_name='regionvit', encoder_depth=5, encoder_weights='None', decoder_pyramid_channels=512,\n",
    "                        decoder_segmentation_channels=128, in_channels=512, classes=2, activation=None)\n",
    "        elif cfg['Model'] == 'RegionViT_UNet':\n",
    "            model = regionvit_unet.RegionViT_UNET()\n",
    "        else:\n",
    "            print('No model found')\n",
    "\n",
    "        checkpoint = torch.load(cfg['Checkpoint'])\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "\n",
    "        # get test data\n",
    "        if cfg['Database'][0] != 'NAKO194':\n",
    "            images_patches_list_test, mask_patches_list_test, images_test, labels_test = data.process_image_data(partition['test'])\n",
    "\n",
    "            test_data = [{\"image\": img, \"label\": label} for img, label in zip(images_patches_list_test, mask_patches_list_test)]\n",
    "            test_dataset_local = data.create_image_space_test_dataset(test_data)\n",
    "\n",
    "            test_loader = DataLoader(test_dataset_local, batch_size=cfg['BatchSize'], shuffle=False,\n",
    "                                      num_workers=8, pin_memory=True)\n",
    "\n",
    "            # select loss function\n",
    "            if cfg['LossFunction'] == 'DiceCELoss':\n",
    "                criterion = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "            elif cfg['LossFunction'] == 'DiceFocalLoss':\n",
    "                criterion = DiceFocalLoss(to_onehot_y=True, focal_weight=[10, 0.1])\n",
    "\n",
    "            # test model\n",
    "            predict(model, test_loader, criterion)\n",
    "\n",
    "            # plot segmentation masks if necessary\n",
    "            if cfg['Plotting'] == True:\n",
    "                data.plot_patient(images_test, labels_test, partition, model, device)\n",
    "\n",
    "        else:\n",
    "            images_test = []\n",
    "            labels_test = []\n",
    "            data.plot_patient(images_test, labels_test, partition, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d40e119-3364-4ad5-81d9-0f6b346d0f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wandb\n",
      "  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/5c/81/1780aa129564b11709a6d7f0739257174f0a3a1b432ba804b3c6f00e0f88/wandb-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading wandb-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb)\n",
      "  Obtaining dependency information for Click!=8.0.0,>=7.1 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for GitPython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/8d/c4/82b858fb6483dfb5e338123c154d19c043305b01726a67d89532b8f8f01b/GitPython-3.1.40-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/lib/python3/dist-packages (from wandb) (5.5.1)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/ee/61/72bf9b0326f77486403f468b0466a3eeb6f7613ba96b714f6974fe6b9c36/sentry_sdk-1.38.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /home/dearadhp/.local/lib/python3.8/site-packages (from wandb) (6.0)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/45/8d/68eec8de2d22a8ed6004344b35f94f2407ba723beee6ab468f162bb7be3e/setproctitle-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading setproctitle-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/dearadhp/.local/lib/python3.8/site-packages (from wandb) (67.8.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/lib/python3/dist-packages (from wandb) (1.4.3)\n",
      "Requirement already satisfied: typing-extensions in /home/dearadhp/.local/lib/python3.8/site-packages (from wandb) (4.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from wandb) (4.23.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.14.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dearadhp/.local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.0.0->wandb)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/96/94/c31f58c7a7f470d5665935262ebd7455c7e4c7782eb525658d3dbf4b9403/urllib3-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: urllib3, smmap, setproctitle, docker-pycreds, Click, sentry-sdk, gitdb, GitPython, wandb\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-auth 2.18.0 requires urllib3<2.0, but you have urllib3 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Click-8.1.7 GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 urllib3-2.1.0 wandb-0.16.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd703a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nibabel\n",
      "  Downloading nibabel-5.1.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources>=1.3 in /home/dearadhp/.local/lib/python3.8/site-packages (from nibabel) (5.12.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/dearadhp/.local/lib/python3.8/site-packages (from nibabel) (1.23.5)\n",
      "Requirement already satisfied: packaging>=17 in /usr/lib/python3/dist-packages (from nibabel) (20.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from importlib-resources>=1.3->nibabel) (3.15.0)\n",
      "Installing collected packages: nibabel\n",
      "Successfully installed nibabel-5.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd134e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: h5py in /home/dearadhp/.local/lib/python3.8/site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/dearadhp/.local/lib/python3.8/site-packages (from h5py) (1.23.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027757c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchio\n",
      "  Obtaining dependency information for torchio from https://files.pythonhosted.org/packages/e8/c0/abed781a834cefb1f469368c72fa8dd28616b2e6bf01e2de3a33c06fe6e3/torchio-0.19.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading torchio-0.19.3-py2.py3-none-any.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m963.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting Deprecated (from torchio)\n",
      "  Obtaining dependency information for Deprecated from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting SimpleITK!=2.0.*,!=2.1.1.1 (from torchio)\n",
      "  Obtaining dependency information for SimpleITK!=2.0.*,!=2.1.1.1 from https://files.pythonhosted.org/packages/86/11/2b55d79c7b5db2cbb77a7acc04b72bdd362602001125ed467a96c141075e/SimpleITK-2.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading SimpleITK-2.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Collecting humanize (from torchio)\n",
      "  Obtaining dependency information for humanize from https://files.pythonhosted.org/packages/aa/2b/2ae0c789fd08d5b44e745726d08a17e6d3d7d09071d05473105edc7615f2/humanize-4.9.0-py3-none-any.whl.metadata\n",
      "  Downloading humanize-4.9.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: nibabel in /home/dearadhp/.local/lib/python3.8/site-packages (from torchio) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/dearadhp/.local/lib/python3.8/site-packages (from torchio) (1.23.5)\n",
      "Requirement already satisfied: scipy in /home/dearadhp/.local/lib/python3.8/site-packages (from torchio) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.1 in /home/dearadhp/.local/lib/python3.8/site-packages (from torchio) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /home/dearadhp/.local/lib/python3.8/site-packages (from torchio) (4.65.0)\n",
      "Collecting typer[all] (from torchio)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch>=1.1->torchio) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (1.12)\n",
      "Requirement already satisfied: networkx in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.1->torchio) (2.10.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.1->torchio) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/dearadhp/.local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.1->torchio) (67.8.0)\n",
      "Requirement already satisfied: wheel in /home/dearadhp/.local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.1->torchio) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/dearadhp/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.1->torchio) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/dearadhp/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.1->torchio) (16.0.6)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/dearadhp/.local/lib/python3.8/site-packages (from Deprecated->torchio) (1.14.1)\n",
      "Requirement already satisfied: importlib-resources>=1.3 in /home/dearadhp/.local/lib/python3.8/site-packages (from nibabel->torchio) (5.12.0)\n",
      "Requirement already satisfied: packaging>=17 in /usr/lib/python3/dist-packages (from nibabel->torchio) (20.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/dearadhp/.local/lib/python3.8/site-packages (from typer[all]->torchio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/lib/python3/dist-packages (from typer[all]->torchio) (0.4.3)\n",
      "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]->torchio)\n",
      "  Obtaining dependency information for shellingham<2.0.0,>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from typer[all]->torchio) (13.4.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from importlib-resources>=1.3->nibabel->torchio) (3.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (2.15.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/dearadhp/.local/lib/python3.8/site-packages (from sympy->torch>=1.1->torchio) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dearadhp/.local/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]->torchio) (0.1.2)\n",
      "Downloading torchio-0.19.3-py2.py3-none-any.whl (172 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.0/173.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SimpleITK-2.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading humanize-4.9.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: SimpleITK, typer, shellingham, humanize, Deprecated, torchio\n",
      "Successfully installed Deprecated-1.2.14 SimpleITK-2.3.1 humanize-4.9.0 shellingham-1.5.4 torchio-0.19.3 typer-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dce9d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting segmentation-models-pytorch\n",
      "  Obtaining dependency information for segmentation-models-pytorch from https://files.pythonhosted.org/packages/cb/70/4aac1b240b399b108ce58029ae54bc14497e1bbc275dfab8fd3c84c1e35d/segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata\n",
      "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.15.2)\n",
      "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting timm==0.9.2 (from segmentation-models-pytorch)\n",
      "  Obtaining dependency information for timm==0.9.2 from https://files.pythonhosted.org/packages/29/90/94f5deb8d76e24a89813aef95e8809ca8fd7414490428480eda19b133d4a/timm-0.9.2-py3-none-any.whl.metadata\n",
      "  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/dearadhp/.local/lib/python3.8/site-packages (from segmentation-models-pytorch) (4.65.0)\n",
      "Requirement already satisfied: pillow in /home/dearadhp/.local/lib/python3.8/site-packages (from segmentation-models-pytorch) (9.5.0)\n",
      "Requirement already satisfied: torch in /home/dearadhp/.local/lib/python3.8/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.1)\n",
      "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
      "  Obtaining dependency information for munch from https://files.pythonhosted.org/packages/56/b3/7c69b37f03260a061883bec0e7b05be7117c1b1c85f5212c72c8c2bc3c8c/munch-4.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: pyyaml in /home/dearadhp/.local/lib/python3.8/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/dearadhp/.local/lib/python3.8/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.15.1)\n",
      "Requirement already satisfied: safetensors in /home/dearadhp/.local/lib/python3.8/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.3.1)\n",
      "Requirement already satisfied: numpy in /home/dearadhp/.local/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/dearadhp/.local/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.10.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/dearadhp/.local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (67.8.0)\n",
      "Requirement already satisfied: wheel in /home/dearadhp/.local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/dearadhp/.local/lib/python3.8/site-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/dearadhp/.local/lib/python3.8/site-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (16.0.6)\n",
      "Requirement already satisfied: fsspec in /home/dearadhp/.local/lib/python3.8/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.6.0)\n",
      "Collecting packaging>=20.9 (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch)\n",
      "  Obtaining dependency information for packaging>=20.9 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dearadhp/.local/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dearadhp/.local/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2019.11.28)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/dearadhp/.local/lib/python3.8/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
      "Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=4343fb57500fe9e2e4cd808e4fae3df126294f6b2a8f695e6e8958d14c11fe6c\n",
      "  Stored in directory: /home/dearadhp/.cache/pip/wheels/84/b9/90/25a0195cf95fb5533db96f1c77ea3f296b7cc86ae8ae48e3dc\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=3869b517fcf602084e80de2e0a7ef6c63d558acffc6e10225e16201de39c4cc5\n",
      "  Stored in directory: /home/dearadhp/.cache/pip/wheels/ed/fa/b9/5c82b59d905f95542a192b883c0cc0082407ea2f54beb2f9e6\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\n",
      "Installing collected packages: packaging, munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab-server 2.22.1 requires jinja2>=3.0.3, but you have jinja2 2.10.1 which is incompatible.\n",
      "nbconvert 7.4.0 requires jinja2>=3.0, but you have jinja2 2.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 packaging-23.2 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "250da94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting yacs\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: PyYAML in /home/dearadhp/.local/lib/python3.8/site-packages (from yacs) (6.0)\n",
      "Installing collected packages: yacs\n",
      "Successfully installed yacs-0.1.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa8bc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting monai\n",
      "  Obtaining dependency information for monai from https://files.pythonhosted.org/packages/08/94/e8a7ba00dd0c7ce959648b562043bd22125d65f5e519e566c822f71bc437/monai-1.3.0-202310121228-py3-none-any.whl.metadata\n",
      "  Downloading monai-1.3.0-202310121228-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/dearadhp/.local/lib/python3.8/site-packages (from monai) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.9 in /home/dearadhp/.local/lib/python3.8/site-packages (from monai) (2.0.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch>=1.9->monai) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (1.12)\n",
      "Requirement already satisfied: networkx in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.9->monai) (2.10.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/dearadhp/.local/lib/python3.8/site-packages (from torch>=1.9->monai) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/dearadhp/.local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->monai) (67.8.0)\n",
      "Requirement already satisfied: wheel in /home/dearadhp/.local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->monai) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/dearadhp/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.9->monai) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/dearadhp/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.9->monai) (16.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/dearadhp/.local/lib/python3.8/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
      "Downloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: monai\n",
      "Successfully installed monai-1.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa769a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
